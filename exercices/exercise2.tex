\section*{exercise 2 (15.04.2016)}
\begin{enumerate}[(1)]
 \item likelihood Funktion: $L(\Theta) = \prod^m_{i=1} h_\Theta(x^{(i)}) (1-h_\Theta(x^{(i)}))^{1-y^{(i)}}$\\
 $h_\Theta(x) = \frac{1}{1+ \exp (- \Theta^T x)}$\\
 \textcolor{red}{ gesucht: $\Theta^k = \stackrel{argmax}{\Theta \in \mathbb{R}^n} l(\Theta) = \stackrel{argmax}{\Theta \in \mathbb{R}^n} \log L(\Theta) = \stackrel{argmax}{\Theta \in \mathbb{R}^n} \Sigma^m_{i=1} y^{(i)} \log h_\Theta(x^{(i)}) + (1-y^{(i)}) \log (1- h_\Theta(x^{(i)}))$}\\
 Ziel heute: Zeige, dass $l(\Theta)$ konkave Funktion ist, d.~h.
 \[l(\alpha \Theta_1 + (1- \alpha) \Theta_2) \geq \alpha l(\Theta_1) + (1-\alpha) l(\Theta_2)\]
\textcolor{red}{Es reicht zu zeigen, dass die Hesse-Matrix von $l(\Theta)$ negativ semidefinit ist.}

%bild
\begin{framed}

\[g(\epsilon) \frac{1}{1+\exp(-\epsilon)} \in (0,1) \quad\quad \text{logistische Funktion}\]
\[\frac{d_g(t)}{dt} = \frac{1}{(1+ \exp (-t))}^2 - \exp(-t) = \frac{1}{1+\exp (-t)} \left(1- \frac{1}{1+\exp (t)}\right)\]
\[g(t)(1-g(t))\]
\[\Rightarrow \frac{\delta h_\Theta(x)}{\delta \Theta_j} = h_\Theta(x)(1-h_\Theta(x)) \frac{\delta}{\delta \Theta_j} \Theta^T x\]
\[= h_\Theta(x)(1-H_\Theta(x))x_j\]
\begin{framed}
Kettenregel
\[h_\Theta(x) = g(\Theta^T x)\]
\[\underbrace{x}_{\substack{\in \mathbb{R}^n}} \underbrace{\mapsto}_{\substack{\text{innere Fkt.}}} \underbrace{\Theta^T}_{\substack{\in \mathbb{R}^n x}} \underbrace{\mapsto}_{\substack{\text{äußere Fkt.}}} \underbrace{g(\Theta^T x)}_{\substack{\in \mathbb{R}^n}}\]
\[\frac{\delta}{\delta \Theta_j} \Theta^T x = \frac{\delta}{\delta\Theta_j}(\Sigma^m_{i=0} \Theta_i x_i) = \frac{\delta}{\delta\Theta_j}(\Theta_1 x_1 + \Theta_1 x_1 + \dots + \Theta_n  x_n) = x_j\]
\end{framed}
\end{framed}


Wir wissen schon: 
\[ \frac{\delta l(\Theta)}{\delta \Theta_j} = \Sigma^m_{i=1}(\underbrace{y^{(i)}}_{\substack{\in \{0,1\}}} - \underbrace{\Theta(x^{(i)}))}_{\substack{\in (0,1)}} x^{(i)}_j\]
\[ \frac{\delta^2 l(\Theta)}{\delta \Theta_k \delta \Theta_j} = \frac{\delta}{\delta \Theta_k }\Sigma^m_{i=1} (y^{(i)} - h_\Theta(x^{(i)})) x_j^{(i)}\]
\[ =\underbrace{\frac{\delta}{\delta \Theta_k} (\Sigma_{i=1}^m y^{(i)} x_j^{(i)})}_{\substack{= 0, \text{hängt nicht von $\Theta$ ab}}} - \frac{\delta}{\delta \Theta_k} (\Sigma^m_{i=1} h_\Theta(x^{(i)}) x_j^{(i)})\]
\[ = \frac{\delta}{\delta \Theta_k} \Sigma^m_{i=1} h_\Theta (x^{(i)}) x_j^{(i)}\]
\[ = - \Sigma^m_{i=1} \frac{\delta}{\delta \Theta_k} (h_\Theta(x^{(i)}) x_j^{(i)})\]
\[ = - \Sigma^m_{i=1} x_j^{(i)} \frac{\delta}{\delta\Theta_k} h_\Theta(x^{(i)})\]
\[ = - \Sigma^m_{i=1} \underbrace{h_\Theta(x^{(i)})}_{\substack{> 0}} \underbrace{(1- h_\Theta(x^{(i)}))}_{\substack{> 0}} x_j^{(i)} x_k^{(i)}\]
Wir müssen zeigen, dass $v^T \quad H(\Theta)v \geq 0$ für alle $v \in \mathbb{R}^n$
\[ \underbrace{H(\Theta)}_{\substack{\in \mathbb{R}^{n \times n}}} = (H_{kj}(\Theta)) = \left( \frac{\delta^2 l(\Theta)}{\delta\Theta_k \delta\Theta_j}\right)\]

%Ich hoffe, dass es ab hier auch wirklich so weiter ging
$H(\Theta)$ ist symmetrisch, da
\[H_{kj}(\Theta) = - \Sigma^m_{i=1} h_\Theta (x^{(i)})(1-h_\Theta (x^{(i)})) x_j^{(i)} x_k^{(i)}\]
\[= - \Sigma^m_{i=1} h_\Theta(x^{(i)})(1-h_\Theta(x^{(i)})) x_k^{(i)}x_j^{(i)}\]
\[= H_{jk}(\Theta) = x_j\]
negativ semi-definit
\[H(\Theta) = - \Sigma^m_{i=1} h_\Theta(x^{(i)})(1-h_\Theta(x^{(i)})) \underbrace{x^{(i)}x^{(i)^T}}\]
\begin{center}
äußeres Produkt des i-ten Datenvektors mit sich selbst
\end{center}
Bsp. Äußeres Produkt:
\[x = \left( \begin{array}{ccc} x_1 \\ x_2 \end{array} \right), \quad x x^T = \left( \begin{array}{ccc} x_1 \\ x_2 \end{array} \right) (x_1 x_2) \]
\[= \left( \begin{array}{ccc} x_1x_1 \quad x_1x_2 \\ x_2x_1 \quad x_2x_2 \end{array} \right) = \left( \begin{array}{ccc} x_1^2 \quad x_1x_2 \\ x_2x_1 \quad x_2^2 \end{array} \right)\]
\[ = \left( \begin{array}{ccc} x_1^2 \quad x_1x_2 \\ x_1x_2 \quad x_2^2 \end{array} \right)\]
\begin{enumerate}[(1)]
\item äußeres Produkt ist symmetrische Matrix
\item äußeres Produkt ist semi-definit
\end{enumerate}
\[v^T (x x^T)v\]
\[= (v^T)(x^T v)\]
\[= (v^T)(v^T x)\]
\[(v^T x)^2 \geq 0\]
\begin{center}
$xx^T$ aus Abbildung $\mathbb{R}^n \mapsto \mathbb{R}^n$\\
$v \mapsto (xx^T)v = x(v^Tx)$
\end{center}

\subsection*{Statistische Modelle}
\begin{enumerate}[1.]
\item lineare Regression: \[p(y,x) = \frac{1}{\sqrt{2 \pi} \sigma} \exp(- \frac{\lVert y- \Theta^T x \lVert^2_2}{2 \sigma^2})\]
\item logistische Regression: \[P[y=1;x] = h_\Theta(x)\]
\[P[y=0;x] = 1-h_\Theta(x)\]
\end{enumerate}

$h_\Theta(x) = \frac{1}{1+\exp(-\Theta^T x)}$ benutzt logistische Funktion $g(z) = \frac{1}{1+\exp(-z)}$
1,2 sind konditionale Modelle, d.h. nur $y$ ist zufällig\\
$y \in \mathbb{R}$ (lineare Regression)\\
$y \in \{0,1\}$ (logistische Regression)\\
$\Rightarrow x$ frei wählbar, Messung von $y$ an der Stelle $x$ ist Zufallsexperiment

\begin{enumerate}
\item[3.] Gauss'sche Diskriminanzanalyse (Klassifikation)
\item[4.] Naive Bayes (Kontingenzanalyse)
\end{enumerate}

3,4 sind generative Modelle, d.h. sowohl $x$ als auch $y$ sind zufällig
\item Likelihood-Funktion der Gauss'schen Diskriminanzanalyse
\[L(\phi,\mu_0, \mu_1, \Sigma) = \prod^m_{i=1} p(x^{(i)},y^{(i)};\phi,\mu_0, \mu_1, \Sigma\]
\[\phi \in [0,1], \quad\quad \mu_0, \mu_1 \in \mathbb{R}^n, \quad\quad \Sigma \in \mathbb{R}^{n \times n} \text{positiv definit}\]
\[\text{Datenpunkte: } (x^{(1)},y^{(1)}, \dots , x^{(m)},y^{(m)})\]

\begin{framed}
Erinnerung: Likelihood-Funktion für logistische Regression:
\[L(\Theta) = \prod^n_{i=1} P[y^{(i)} | x^{(i)}, \Theta]\]
\end{framed}

\begin{framed}
Unterscheidung:
\begin{enumerate}[1.]
\item Zufallsvariable $x$ nimmt nur endlich viele Werte $\{1, \dots , k\}$ an. Dann kann $x = i$ eine Wahrscheinlichkeit $P[x = i]$ zuordnen.
\item Zufallsvariable $x$ nimmt Werte in $\mathbb{R}$ an. Dann kann man den Ereignissen $X \in [a,b]$ eine Wahrscheinlichkeit zuordnen $P[X \in [a,b]] = \int^b_a p(x) dx$. Dabei ist $p:\mathbb{R} \rightarrow \mathbb{R}$ eine Wahrscheinlichkeitsdichte, d.h.

\begin{enumerate}[(1.)]
\item $\int^\infty_{- \infty} p(x) dx = 1$
\item $p(x) \geq 0$
\end{enumerate}
\end{enumerate}
\end{framed}

\begin{framed}
 Bayes Theorem:
 \[p(x|y) = \frac{p(x,y)}{p(y)}\]
 \[\Rightarrow p(x,y) = p(x|y)p(y)\]
\end{framed}
\[= \prod^m_{i=1} p(x^{(i)} | y^{(i)} ; \mu_0, \mu_1, \Sigma) P(y^{(i)}; \phi)\]
\[= \prod^m_{i=1} p(x^{(i)} | y^{(i)} = 1; \mu_0, \Sigma)^{y^{(i)}} p(x^{(i)} | y^{(i)} = 0 ; \mu_1, \Sigma)^{1-y^{(i)}}\]
\[= \left( \frac{1}{(2\pi)^{\frac{a}{2}}} |\Sigma|^{\frac{1}{2}}\right)^m \prod^m_{i=1} \exp(- \frac{1}{2}) (x^{(i)} \mu_1)^T \Sigma^{-1} (x^{(i)} - \mu_1))^{1-y^{(i)}} \exp(- \frac{1}{2}(x^{(i)} - \mu_0)^T \Sigma^{-1}(x^{(i)}-\mu_0))^{1-y^{(i)}}\]
\[ \dots \phi^{y^{(i)}}(1-\phi)^{1-y^{(i)}}\]

Notationeller Trick:
\[a^{y^{(i)}} = a^{\tilde{x}_{\{y^{(i)} = 1\}}}\]
\[\tilde{x}_{\{y^{(i)} = 1\}} = =\begin{cases}1&1, \text{falls } y^{(i)} = 1\\2&0, \text{falls } y^{(i)} = 0\end{cases}\]

\[= \left( \frac{1}{(2\pi)^{\frac{a}{2}}} |\Sigma|^{\frac{1}{2}}\right)^m \prod^m_{i=1} \exp (- \frac{1}{2} (x^{(i)} - \mu_1)^T \Sigma^{-1} (x^{(i)} - \mu_1))^{\tilde{x}_{\{y^{(i)} = 1\}}} * \]
\[\exp (- \frac{1}{2} (x^{(i)} - \mu_0) \Sigma^{-1} (x^{(i)} - \mu_0 ))^{\tilde{x}_{\{y^{(i)} = 0\}}} * \dots *\]
\[\phi^{y^{(i)}} (1-\phi^{1-y^{(i)}})\]
\end{enumerate}

Merkregel: Die Likelihood-Funktion ist die Wahrscheinlichkeit der Beobachtungen als Funktion der Parameter.\\
Da es einfach ist, mit Summen als mit Produkten zu arbeiten: Übergang zur $\log$-Likelihood-Funktion
\[ l (\phi, \mu_0, \mu_1, \Sigma) = \log L(\phi, \mu_0, \mu_1, \Sigma)\]
\[= -m \log ((2\pi)^{\frac{n}{2}} |\Sigma|^{\frac{1}{2}})\]
\[- \Sigma^n_{i=1} \tilde{x}_{\{y^{(i)} = 1\}} (x^{(i)} - \mu_1)^T \Sigma^{-1} (x^{(i)}-\mu_0)\]
\[- \Sigma^n_{i=1} \tilde{x}_{\{y^{(i)} = 0\}} (x^{(i)} -\mu_0)^T \Sigma^{-1} (x^{(i)} - \mu_1)\]
\[+ \Sigma^m_{i=1} (y^{(i)} \log \phi + (1-y^{(i)}) \log (1-\phi))\]
Für die max. Likelihood-Schätzung von $\phi$, d.h. bestimme desjenigen $\phi$, das $\log$-Likelihood-Funktion maximiert. Notwendig, dass Ableitung nach $\phi$ verschwindet.
\[\frac{d l(\phi,\mu_0,\mu_1,\Sigma)}{d\phi} = \Sigma^m_{i=1} \frac{y^{(i)}}{\phi} - \frac{(1-y^{(i)})}{1-\phi} \stackrel{!}{=} 0\]
\[\Rightarrow (1-\phi) \Sigma^m_{i=1} y^{(i)} \stackrel{!}{=} \phi \Sigma^m_{i=1} 1-y^{(i)} \Rightarrow \Sigma^m_{i=1} 1 = m_i \phi\]
%bei m_i \phi bin ich mir nicht sicher! Bitte nochmal drübersehen
\begin{framed}
\[\Rightarrow \phi = \frac{1}{m} \Sigma^m_{i=1} y^{(i)}\]
\begin{center}
Max. Likelihood-Schätzung für $\phi$
\end{center}
\end{framed}

Maximierung der Likelihood-Schätzung von $\mu_1$. Beachte: $\mu_1 \in \mathbb{R}^n$. Notwendig für Maximum der $\log$-Likelihood-Funktion ist das Verschwinden des Gradienten nach $\mu_1$.
\[\bigtriangledown_{\mu_1} l(\phi, \mu_0, \mu_1, \Sigma) = \bigtriangledown_{\mu_0} (- \frac{1}{2} \Sigma^m_{i=1} \tilde{x}_{\{y^{(i)} = 1\}} (x^{(i)}-\mu_1)^T \Sigma^{-1} (x^{(i)} - \mu_1))\]
\[= - \frac{1}{2} \Sigma^m_{i=1} \tilde{x}_{\{y^{(i)} = 1\}} \bigtriangledown_{\mu_1}\]
\[(\underbrace{(x^{(i)} - \mu_1)^T \Sigma^{-1} (x^{(i)} - \mu_1)}_{\substack{= x^{(i)} \Sigma^{-1} x^{(i)} -2\mu_1^T \Sigma^{-1} x^{(i)} + \mu_1^T \Sigma^{-1}}})\]
\[= - \frac{1}{2} \Sigma^m_{i=1} \tilde{x}_{\{y^{(i)} = 1\}} (-2 \Sigma^{-1} x^{(i)} + 2 \Sigma^{-1} \mu_1)\]
\[\Sigma^m_{i=1} \tilde{x}_{\{y^{(i)} = 1\}} \Sigma^{-1} \mu_1 - \Sigma^{-1} x^{(i)}\]
\[\Sigma^m_{i=1} \tilde{x}_{\{x^{(i)} = 1\}} \Sigma^{-1} (\mu_1 - x^{(i)})\]
\[\Sigma^{-1} (\Sigma^m_{i=1} \tilde{x}_{\{y^{(i)} = 1\}} (\mu_1 - x^{(i)})) \stackrel{!}{=} 0\]

\begin{framed}
Erinnerung: $\Sigma$ ist positiv definit
\begin{itemize}
\item $\Rightarrow \Sigma$ ist invertierbar
\item $\Rightarrow \Sigma^{-1}$ ist invertierbar 
\end{itemize}
\[\Sigma\Sigma^{-1} = \Sigma^{-1}\Sigma = \mathds{1}_n = \left( \begin{array}{ccc} 1 \quad\quad 0 \\ \ddots \\ 0 \quad\quad 1 \end{array}\right) \in \mathbb{R}^{n \times n}\]
\end{framed}
Situation:
\[\Sigma^{-1} v = 0\]
\[\Rightarrow \Sigma\Sigma^{-1} v = \Sigma * 0 = 0\]
\[\mathds{1}_n v = 0\]
\[\Rightarrow v = 0\]
Hier:
\[v = \Sigma^m_{i=1} \tilde{x}_{\{y^{(i)}= 1\}} (\mu_1 - x^{(i)})\]
\[\Rightarrow \Sigma^m_{i=1} \tilde{x}_{\{y^{(i)}=1\}} (\mu_1 - x^{(i)}) = 0\]
\[\Rightarrow \mu_1 \Sigma^m_{i=1} \tilde{x}_{\{ y^{(i)} = 1\}} = \Sigma^m_{i=1} \tilde{x}_{\{y^{(i)}=1\}} x^{(i)}\]
\begin{framed}
\[\Rightarrow \mu_1 = \frac{\Sigma^m_{i=1}\tilde{x}_{\{y^{(i)}=1\}} x^{(i)}}{\Sigma^m_{i=1}\tilde{x}_{\{y^{(i)}=1\}}}\]
\begin{center}
Maximierung der Likelihood-Schätzung von $\mu_1$
\end{center}
\end{framed}
Analog (Symmetrie):
\begin{framed}
\[\Rightarrow \mu_1 = \frac{\Sigma^m_{i=1}\tilde{x}_{\{y^{(i)}=0\}} x^{(i)}}{\Sigma^m_{i=1}\tilde{x}_{\{y^{(i)}=0\}}}\]
\begin{center}
Maximierung der Likelihood-Schätzung von $\mu_0$
\end{center}
\end{framed}


